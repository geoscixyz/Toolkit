{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimPEG import Utils\n",
    "from SimPEG.Utils import mkvc\n",
    "import SimPEG.PF as PF\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import geosoft.gxpy.grid as gxgrd\n",
    "import geosoft.gxpy.gx as gx\n",
    "from matplotlib.patches import Rectangle\n",
    "gxc = gx.GXpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workDir = 'C:\\\\Users\\\\DominiqueFournier\\\\Desktop\\\\Search_mag_data\\\\'\n",
    "# fname = 'Search_reduced_columns.csv'\n",
    "\n",
    "# workDir = 'C:\\\\Users\\DominiqueFournier\\\\Dropbox\\\\MDRU_GIF_shared_files\\\\GBC_Search_grd\\\\'\n",
    "# fName = 'Enhanced_Mag_UTM09_GSC.GRD'\n",
    "\n",
    "workDir =r\"C:\\Users\\DominiqueFournier\\Downloads\\AnomalousMagneticField_updatedApr17\"\n",
    "fName = '\\MAG_UTM09.grd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corners for cropping data (NAD 83, Zone 9)\n",
    "SW 649000 E, 6049000 N\n",
    "NE 690000 E, 6090000 N\n",
    "\n",
    "If too large, this one is slightly smaller\n",
    "SW 656000 E, 6050000 N\n",
    "NE 686000 E, 6082000 N\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gxgrd.Grid(workDir+fName) as grid:\n",
    "#     extent = grid.extent_2d()\n",
    "g = gxgrd.Grid.open(workDir + fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0,2,1,3], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extent_2d[np.array([0,2,1,3], dtype='int')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the grid extent and coordinate system from which we will create a default map named after the grid\n",
    "# do this in a separate `with...` as the Aggregate_group class needs access to the grid file.\n",
    "with gxgrd.Grid(workDir + fName) as grid:\n",
    "\n",
    "    extent = grid.extent_2d()\n",
    "    coordinate_system = grid.coordinate_system\n",
    "    data_values = grid.xyzv()[:, :, 3]\n",
    "    nx, ny = grid.nx, grid.ny\n",
    "    dx, dy = grid.dx, grid.dy\n",
    "#     extent_2d = grid.extent_2d()\n",
    "    x0, y0 = grid.x0, grid.y0\n",
    "\n",
    "vectorCCx, vectorCCy = np.asarray(range(nx))*dx+x0,np.asarray(range(ny))*dy+y0 \n",
    "extent = np.r_[vectorCCx[0], vectorCCx[-1], vectorCCy[0], vectorCCy[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = np.r_[649000, 690000, 6049000, 6090000]\n",
    "# lims = np.r_[np.c_[2500000, 4500000], np.c_[3000000, 5000000]]\n",
    "             \n",
    "fig, axs = plt.figure(figsize=(10,6)), plt.subplot(1,2,1)\n",
    "\n",
    "plt.imshow(data_values, extent=extent, origin='lower', cmap='RdBu_r', vmin=-200, vmax=800)\n",
    "\n",
    "axs.add_patch(Rectangle((lims[0], lims[2]),\n",
    "                               lims[1]-lims[0],\n",
    "                               lims[3]-lims[2],\n",
    "                               facecolor='none', edgecolor='k'))\n",
    "\n",
    "\n",
    "# Extract data within window and plot\n",
    "indx = (vectorCCx > lims[0]) * (vectorCCx < lims[1])\n",
    "indy = (vectorCCy > lims[2]) * (vectorCCy < lims[3])\n",
    "\n",
    "subData = data_values[:, indx]\n",
    "subData = subData[indy, :]\n",
    "# fig, \n",
    "axs = plt.subplot(1,2,2)\n",
    "\n",
    "plt.imshow(subData, extent=lims, origin='lower', cmap='RdBu_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def progress(iter, prog, final):\n",
    "#     \"\"\"\n",
    "#     progress(iter,prog,final)\n",
    "\n",
    "#     Function measuring the progress of a process and print to screen the %.\n",
    "#     Useful to estimate the remaining runtime of a large problem.\n",
    "\n",
    "#     Created on Dec, 20th 2015\n",
    "\n",
    "#     @author: dominiquef\n",
    "#     \"\"\"\n",
    "#     arg = np.floor(float(iter)/float(final)*10.)\n",
    "\n",
    "#     if arg > prog:\n",
    "\n",
    "#         print(\"Done \" + str(arg*10) + \" %\")\n",
    "#         prog = arg\n",
    "\n",
    "#     return prog\n",
    "\n",
    "# dataMat = []\n",
    "# count = -1\n",
    "# for ii, line in enumerate(dtaMat):\n",
    "#     lst = re.findall('\\d*\\.\\d*', line)\n",
    "    \n",
    "#     if len(lst) == 6:\n",
    "#         dataMat.append([float(i) for i in lst])\n",
    "        \n",
    "#     count = progress(ii, count, len(dtaMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub sample to Dianne's extent\n",
    "# lims = np.r_[np.c_[649000, 6049000],\n",
    "# np.c_[690000, 6090000]]\n",
    "lims = np.r_[np.c_[649000, 6049000],\n",
    "np.c_[690000, 6090000]]\n",
    "\n",
    "ind = (dataMat[:,4] > lims[0,0]) *(dataMat[:,4] < lims[1,0])*(dataMat[:,5] > lims[0,1])*(dataMat[:,5] < lims[1,1])\n",
    "\n",
    "subset = dataMat[ind,:]\n",
    "\n",
    "\n",
    "# plt.scatter(subset[:,4], subset[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(workDir+'Search_reduced_columnsSubset.xyz', subset, fmt='%.8e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dType = 'XYZ'\n",
    "method = ('radius', 100)#('random', 0.1)  # #\n",
    "\n",
    "dFileOut = 'Search_reduced_columns_DwnS100m.dat'\n",
    "\n",
    "def downSample(dFile,dType):\n",
    "    # # SCRIPT STARTS HERE # #\n",
    "    if dType == 'MAG':\n",
    "        survey = PF.Magnetics.readMagneticsObservations(workDir + '\\\\' + dFile)\n",
    "        locXYZ = survey.srcField.rxList[0].locs\n",
    "    elif dType == 'GRAV':\n",
    "        survey = PF.Gravity.readUBCgravObs(workDir + '\\\\' + dFile)\n",
    "        locXYZ = survey.srcField.rxList[0].locs\n",
    "    elif dType == 'XYZ':\n",
    "    #     survey = np.loadtxt(workDir + \"\\\\\" + dFile, skiprows=1)\n",
    "        locXYZ = dataMat[:, 4:]\n",
    "    else:\n",
    "        assert dType in ['MAG', 'GRAV', 'XYZ'], \"dType must be 'MAG' or 'GRAV'\"\n",
    "\n",
    "    # Downsample the survey using specified method\n",
    "    assert method[0] in ['radius', 'random'], \"Downsample method should be 'radius' or 'random' \"\n",
    "\n",
    "\n",
    "    def progress(iter, prog, final):\n",
    "        \"\"\"\n",
    "        progress(iter,prog,final)\n",
    "\n",
    "        Function measuring the progress of a process and print to screen the %.\n",
    "        Useful to estimate the remaining runtime of a large problem.\n",
    "\n",
    "        Created on Dec, 20th 2015\n",
    "\n",
    "        @author: dominiquef\n",
    "        \"\"\"\n",
    "        arg = np.floor(float(iter)/float(final)*10.)\n",
    "\n",
    "        if arg > prog:\n",
    "\n",
    "            print(\"Done \" + str(arg*10) + \" %\")\n",
    "            prog = arg\n",
    "\n",
    "        return prog\n",
    "\n",
    "\n",
    "    if method[0] == 'radius':\n",
    "\n",
    "        nstn = locXYZ.shape[0]\n",
    "        # Initialize the filter\n",
    "        indx = np.ones(nstn, dtype='bool')\n",
    "\n",
    "        count = -1\n",
    "        print(\"Begin filtering for radius= \" + str(method[1]))\n",
    "\n",
    "        for ii in range(nstn):\n",
    "\n",
    "            if indx[ii]:\n",
    "\n",
    "                rad = ((locXYZ[ii, 0] - locXYZ[:, 0])**2 +\n",
    "                       (locXYZ[ii, 1] - locXYZ[:, 1])**2)**0.5\n",
    "\n",
    "                indx[rad < method[1]] = False\n",
    "                indx[ii] = True\n",
    "\n",
    "            count = progress(ii, count, nstn)\n",
    "\n",
    "\n",
    "    elif method[0] == 'random':\n",
    "\n",
    "        nD = int(locXYZ.shape[0]*method[1])\n",
    "        print(\"nD ratio:\" + str(nD) + '\\\\' + str(locXYZ.shape[0]))\n",
    "        indx = np.random.randint(0, high=locXYZ.shape[0], size=nD)\n",
    "\n",
    "\n",
    "    # Create a new downsampled survey\n",
    "    if dType == 'MAG':\n",
    "\n",
    "        rxLoc = PF.BaseGrav.RxObs(locXYZ[indx, :])\n",
    "        srcField = PF.BaseMag.SrcField([rxLoc], param=survey.srcField.param)\n",
    "        survey_dwnS = PF.BaseMag.LinearSurvey(srcField)\n",
    "        survey_dwnS.dobs = survey.dobs[indx]\n",
    "        survey_dwnS.std = survey.std[indx]\n",
    "\n",
    "#         PF.Magnetics.writeUBCobs(workDir + '\\\\' + dFileOut, survey_dwnS)\n",
    "\n",
    "    elif dType == 'GRAV':\n",
    "\n",
    "        rxLoc = BaseGrav.RxObs(locXYZ[indx, :])\n",
    "        srcField = BaseGrav.SrcField([rxLoc])\n",
    "        survey_dwnS = BaseGrav.LinearSurvey_dwnS(srcField)\n",
    "        survey_dwnS.dobs = survey.dobs[indx]\n",
    "        survey_dwnS.std = survey.std[indx]\n",
    "\n",
    "#         PF.Gravity.writeUBCobs(workDir + '\\\\' + dFileOut, survey_dwnS)\n",
    "\n",
    "    elif dType == 'XYZ':\n",
    "\n",
    "        # vec = np.zeros(locXYZ.shape[0], dtype='bool')\n",
    "        # vec[indx] = True\n",
    "        # indx = np.all([vec, locXYZ[:,0] > 479000, locXYZ[:,1] > 6910000,\n",
    "        #                locXYZ[:,0] < 670000, locXYZ[:,1] < 7009000], axis=0)\n",
    "        survey_dwnS = dataMat[indx, :]  # np.c_[survey[indx, :2],survey[indx, -1]]\n",
    "#         np.savetxt(workDir + '\\\\' + dFileOut, survey_swnS)\n",
    "    return survey_dwnS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
